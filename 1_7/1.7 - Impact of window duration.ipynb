{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Patatone/Network-failure-cause-identification/blob/main/Failure_cause_identification_with_different_failures_location_IPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f-Dgj8rcVvCZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "import time\n",
    "import sklearn.metrics as mt\n",
    "import pickle\n",
    "\n",
    "from xgboost import Booster\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wtkni_HDVvCg"
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "###### The function load_window_dataset() that takes in input window data file, and \n",
    "###### label to be assigned and returns numpy arrays with features and labels\n",
    "#################################################################################################\n",
    "\n",
    "def load_window_dataset(X, y, filename, label):\n",
    "#Inputs: - X: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only features)\n",
    "#        - y: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only labels)\n",
    "#        - filename: full name (with path) of the file to be read (it must be a window dataset file created above)\n",
    "#        - label: integer, label to be assigned to the datapoints retrieved from filename; it may differ from labels already included in current y\n",
    "#Outputs: - X: updated X (including features for the new data points retrieved from filename)\n",
    "#         - y: updated y (including labels for the new data points)\n",
    "#This function to X and y in input the new datapoints retrieved from filename and return updated X and y\n",
    "#The function handle the case when X and y are empty (initialized as None)\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    if X is None:\n",
    "        X = data.to_numpy()\n",
    "        # full() function puts in all X.shape[0] elements the value \"label\"\n",
    "        y = np.full(X.shape[0], label)\n",
    "    else:\n",
    "        X_temp = data.to_numpy()\n",
    "        y_temp = np.full(X_temp.shape[0], label)\n",
    "        X = np.append(X, X_temp, axis = 0) #F: axis=0-->stack X and X_temp vertically (increase no of rows)\n",
    "        y = np.append(y, y_temp)\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i6dGWj1QVvCj"
   },
   "outputs": [],
   "source": [
    "def train_classifier_XGB(X_train, y_train): \n",
    "    xgb = XGBClassifier(eta = 0.7, max_depth= 19, subsample = 0.7, verbosity = 0)\n",
    "    \n",
    "    # Execute the traning 3 times to be sure that the training time is correct\n",
    "    ttimes = []\n",
    "    for i in range(0, 3):\n",
    "        t0 = time.time()\n",
    "        xgb.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        ex_time = t1 - t0\n",
    "        ttimes.append(ex_time)\n",
    "        print(ex_time)\n",
    "\n",
    "    return xgb, ttimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a0aJlN6lVvCl"
   },
   "outputs": [],
   "source": [
    "def train_classifier_DNN(X_train, y_train): \n",
    "    size = (10,) * 3\n",
    "    dnn = MLPClassifier(hidden_layer_sizes=size, activation='logistic',\n",
    "                                solver='adam', learning_rate='invscaling', max_iter=1000)\n",
    "    \n",
    "    # Execute the traning 3 times to be sure that the training time is correct\n",
    "    ttimes = []\n",
    "    for i in range(0, 3):\n",
    "        t0 = time.time()\n",
    "        dnn.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        ex_time = t1 - t0\n",
    "        ttimes.append(ex_time)\n",
    "\n",
    "    return dnn, ttimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SHnCDjAsPrmp"
   },
   "outputs": [],
   "source": [
    "def train_classifier_KNN(X_train, y_train): \n",
    "    knn = KNeighborsClassifier(leaf_size=21, p=2, n_neighbors=4)\n",
    "    \n",
    "    # Execute the traning 3 times to be sure that the training time is correct\n",
    "    ttimes = []\n",
    "    for i in range(0, 3):\n",
    "        t0 = time.time()\n",
    "        knn.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        ex_time = t1 - t0\n",
    "        ttimes.append(ex_time)\n",
    "        print(ex_time)\n",
    "\n",
    "    return knn, ttimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dosJAeJhVvCm"
   },
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "###### The function performance_eval() takes in input ground truth and predicted labels, \n",
    "###### prints results in a result file passed in input, and returns global metrics\n",
    "########################################################################################################\n",
    "\n",
    "def performance_eval(y_true, y_pred, lab, l_names):\n",
    "\n",
    "    #Compute metrics and print/write them\n",
    "    accuracy = mt.accuracy_score(y_true, y_pred)\n",
    "    precision = mt.precision_score(y_true, y_pred, labels=lab, average=None) #F: average=None gives per-class results\n",
    "    global_precision = mt.precision_score(y_true, y_pred, labels=lab, average='weighted') \n",
    "    recall = mt.recall_score(y_true, y_pred, labels=lab, average=None)\n",
    "    global_recall = mt.recall_score(y_true, y_pred, labels=lab, average='weighted') \n",
    "    f1score = mt.f1_score(y_true, y_pred, labels=lab, average=None)\n",
    "    global_f1score = mt.f1_score(y_true, y_pred, labels=lab, average='weighted')\n",
    "\n",
    "    return accuracy, global_precision, global_recall, global_f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************\n",
      "Iteration for spacing=1 and window length=10\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=20\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=30\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=40\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=50\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=60\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=70\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=80\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=90\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n",
      "Training KNN...\n",
      "********************************\n",
      "Iteration for spacing=1 and window length=100\n",
      "1) Loading dataset into (XX,yy)...\n",
      "Training XGB...\n",
      "Training DNN...\n"
     ]
    }
   ],
   "source": [
    "#F: these params will be used to iterate over different values of window length...\n",
    "windowrange=list(range(10,101,10))\n",
    "#F: ...and window spacing (if needed)\n",
    "spacingrange=[1]\n",
    "\n",
    "lbl = [0, 1]\n",
    "label_names=['Attenuation', 'Filtering']\n",
    "\n",
    "A_XGB = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GP_XGB = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GR_XGB = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GF1_XGB = np.zeros([len(spacingrange),len(windowrange)])\n",
    "\n",
    "A_DNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GP_DNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GR_DNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GF1_DNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "\n",
    "A_KNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GP_KNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GR_KNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "GF1_KNN = np.zeros([len(spacingrange),len(windowrange)])\n",
    "\n",
    "xgb_all_ttimes = []\n",
    "dnn_all_ttimes = []\n",
    "knn_all_ttimes = []\n",
    "\n",
    "for i, spacing in enumerate(spacingrange): #enumerate(range(minsp,maxsp+1,stepsp)):\n",
    "    for j, length in enumerate(windowrange): #enumerate(range(minlength,maxlength+1,steplength)):\n",
    "        print('********************************')\n",
    "        print('Iteration for spacing={} and window length={}'.format(spacing,length))\n",
    "        \n",
    "        ####### 1) Load dataset #######\n",
    "        print('1) Loading dataset into (XX,yy)...')\n",
    "        \n",
    "        XX = None\n",
    "        yy = None\n",
    "        folderpath='../Features_with_norm'\n",
    "        \n",
    "        for filename in os.listdir(folderpath):\n",
    "            if filename.endswith('_sp' + str(spacing) + '_w' + str(length) + '.dat'):\n",
    "                label = 0\n",
    "                if int(filename[9]) > 5:\n",
    "                    label = 1\n",
    "                fullname = folderpath + '/' + filename\n",
    "\n",
    "                XX, yy = load_window_dataset(XX, yy, fullname, label)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        XX = scaler.fit_transform(XX)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(XX, yy, stratify=yy, test_size=0.3, random_state=42)\n",
    "        print('Training XGB...')\n",
    "        xgb, xgb_ttimes = train_classifier_XGB(X_train, y_train)\n",
    "\n",
    "        print('Training DNN...')\n",
    "        dnn, dnn_ttimes = train_classifier_DNN(X_train, y_train)\n",
    "        \n",
    "        print('Training KNN...')\n",
    "        knn, knn_ttimes = train_classifier_KNN(X_train, y_train)\n",
    "\n",
    "        xgb_all_ttimes.append(xgb_ttimes)\n",
    "        dnn_all_ttimes.append(dnn_ttimes)\n",
    "        knn_all_ttimes.append(knn_ttimes)\n",
    "    \n",
    "        y_pred_XGB = xgb.predict(X_test)\n",
    "        y_pred_DNN = dnn.predict(X_test)\n",
    "        y_pred_KNN = knn.predict(X_test)\n",
    "\n",
    "        A_XGB[i,j], GP_XGB[i,j], GR_XGB[i,j], GF1_XGB[i,j] = performance_eval(y_test, y_pred_XGB, lbl, label_names)\n",
    "        A_DNN[i,j], GP_DNN[i,j], GR_DNN[i,j], GF1_DNN[i,j] = performance_eval(y_test, y_pred_DNN, lbl, label_names)\n",
    "        A_KNN[i,j], GP_KNN[i,j], GR_KNN[i,j], GF1_KNN[i,j] = performance_eval(y_test, y_pred_KNN, lbl, label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowrange_lables = [str(x) for x in windowrange]\n",
    "    \n",
    "def candle_trainng_size_impact(fig_folder, alg_name, ttimes):\n",
    "    global windowrange\n",
    "    global windowranges_lables\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,8))\n",
    "    bplots = []\n",
    "    n_perc = len(windowrange)\n",
    "    \n",
    "    for i in range(n_perc):\n",
    "        bplots.append(ax.boxplot(ttimes[i], positions = [i], patch_artist=True))\n",
    "\n",
    "    for bplot in bplots:\n",
    "        for patch in bplot['boxes']:\n",
    "            patch.set_facecolor('lightblue')\n",
    "    \n",
    "    plt.xticks(color='black')\n",
    "    plt.yticks(color='black')\n",
    "    plt.grid(1)\n",
    "    plt.xticks(ticks = list(range(n_perc)), labels = windowrange_lables, fontsize = 14)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), ha=\"center\") \n",
    "    plt.ylabel('Seconds', color='black', fontsize=14)\n",
    "    image_title=alg_name+' Window duration impact on Traning Time'\n",
    "    plt.title(image_title, fontsize=14)\n",
    "    plt.show()\n",
    "    fig.savefig(fig_folder+'/'+image_title.replace(\" \", \"_\")+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder = '1_7_Figures'\n",
    "if not os.path.exists(fig_folder):\n",
    "    os.makedirs(fig_folder)\n",
    "\n",
    "candle_trainng_size_impact(fig_folder, 'XGB', xgb_all_ttimes)\n",
    "candle_trainng_size_impact(fig_folder, 'MLP', dnn_all_ttimes)\n",
    "candle_trainng_size_impact(fig_folder, 'KNN', knn_all_ttimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "###### Plot the 4 metrics vs window length in 4 separate graphs\n",
    "###### each graph should include one curve for each ML algorithm\n",
    "###############################################################################\n",
    "\n",
    "xvalues=np.array(windowrange)\n",
    "\n",
    "A_XGB = A_XGB.reshape(-1, 1)\n",
    "GP_XGB = GP_XGB.reshape(-1, 1)\n",
    "GR_XGB = GR_XGB.reshape(-1, 1)\n",
    "GF1_XGB = GF1_XGB.reshape(-1, 1)\n",
    "\n",
    "A_DNN = A_DNN.reshape(-1, 1)\n",
    "GP_DNN = GP_DNN.reshape(-1, 1)\n",
    "GR_DNN = GR_DNN.reshape(-1, 1)\n",
    "GF1_DNN = GF1_DNN.reshape(-1, 1)\n",
    "\n",
    "A_KNN = A_KNN.reshape(-1, 1)\n",
    "GP_KNN = GP_KNN.reshape(-1, 1)\n",
    "GR_KNN = GR_KNN.reshape(-1, 1)\n",
    "GF1_KNN = GF1_KNN.reshape(-1, 1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharex='all')\n",
    "\n",
    "axs[0,0].plot(xvalues, A_XGB, label = 'XGB')\n",
    "axs[0,0].plot(xvalues, A_DNN, label = 'DNN')\n",
    "axs[0,0].plot(xvalues, A_KNN, label = 'KNN')\n",
    "axs[0,0].set_title('Accuracy')\n",
    "axs[0,0].set_ylabel('Accuracy')\n",
    "axs[0,0].yaxis.grid(True)\n",
    "\n",
    "axs[0,1].plot(xvalues, GP_XGB, label = 'XGB')\n",
    "axs[0,1].plot(xvalues, GP_DNN, label = 'DNN')\n",
    "axs[0,1].plot(xvalues, GP_KNN, label = 'KNN')\n",
    "axs[0,1].set_title('Precision')\n",
    "axs[0,1].set_ylabel('Precision')\n",
    "axs[0,1].yaxis.grid(True)\n",
    "\n",
    "axs[1,0].plot(xvalues, GR_XGB, label = 'XGB')\n",
    "axs[1,0].plot(xvalues, GR_DNN, label = 'DNN')\n",
    "axs[1,0].plot(xvalues, GR_KNN, label = 'KNN')\n",
    "axs[1,0].set_title('Recall')\n",
    "axs[1,0].set_ylabel('Recall')\n",
    "axs[1,0].yaxis.grid(True)\n",
    "\n",
    "axs[1,1].plot(xvalues, GP_XGB, label = 'XGB')\n",
    "axs[1,1].plot(xvalues, GP_DNN, label = 'DNN')\n",
    "axs[1,1].plot(xvalues, GP_KNN, label = 'KNN')\n",
    "axs[1,1].set_title('F1-Score')\n",
    "axs[1,1].set_ylabel('F1-Score')\n",
    "axs[1,1].yaxis.grid(True)\n",
    "\n",
    "axs[1,0].set_xlabel('Window length, s')\n",
    "axs[1,1].set_xlabel('Window length, s')\n",
    "\n",
    "\n",
    "axs[1,1].legend(loc='best')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_folder+'/metrics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
