{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f-Dgj8rcVvCZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marsl\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "import time\n",
    "import sklearn.metrics as mt\n",
    "import pickle\n",
    "\n",
    "from xgboost import Booster\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Wtkni_HDVvCg"
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "###### The function load_window_dataset() that takes in input window data file, and \n",
    "###### label to be assigned and returns numpy arrays with features and labels\n",
    "#################################################################################################\n",
    "\n",
    "def load_window_dataset(X, y, filename, label):\n",
    "#Inputs: - X: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only features)\n",
    "#        - y: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only labels)\n",
    "#        - filename: full name (with path) of the file to be read (it must be a window dataset file created above)\n",
    "#        - label: integer, label to be assigned to the datapoints retrieved from filename; it may differ from labels already included in current y\n",
    "#Outputs: - X: updated X (including features for the new data points retrieved from filename)\n",
    "#         - y: updated y (including labels for the new data points)\n",
    "#This function to X and y in input the new datapoints retrieved from filename and return updated X and y\n",
    "#The function handle the case when X and y are empty (initialized as None)\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    if X is None:\n",
    "        X = data.to_numpy()\n",
    "        # full() function puts in all X.shape[0] elements the value \"label\"\n",
    "        y = np.full(X.shape[0], label)\n",
    "    else:\n",
    "        X_temp = data.to_numpy()\n",
    "        y_temp = np.full(X_temp.shape[0], label)\n",
    "        X = np.append(X, X_temp, axis = 0) #F: axis=0-->stack X and X_temp vertically (increase no of rows)\n",
    "        y = np.append(y, y_temp)\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcvMwMfcVvCi",
    "outputId": "371a06b4-3fa7-42a0-efd9-c045e832947f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario_1_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (21591, 6)\n",
      "current shape of y: (21591,)\n",
      "Scenario_1_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (43182, 6)\n",
      "current shape of y: (43182,)\n",
      "Scenario_1_monitor_node_1_preamp_lpth_3-2_1_sp1_w10.dat\n",
      "current shape of X: (64773, 6)\n",
      "current shape of y: (64773,)\n",
      "Scenario_2_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (86364, 6)\n",
      "current shape of y: (86364,)\n",
      "Scenario_2_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (107955, 6)\n",
      "current shape of y: (107955,)\n",
      "Scenario_3_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (129546, 6)\n",
      "current shape of y: (129546,)\n",
      "Scenario_4_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (151137, 6)\n",
      "current shape of y: (151137,)\n",
      "Scenario_4_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (172728, 6)\n",
      "current shape of y: (172728,)\n",
      "Scenario_4_monitor_node_1_preamp_lpth_3-2_1_sp1_w10.dat\n",
      "current shape of X: (194319, 6)\n",
      "current shape of y: (194319,)\n",
      "Scenario_5_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (215910, 6)\n",
      "current shape of y: (215910,)\n",
      "Scenario_5_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (237500, 6)\n",
      "current shape of y: (237500,)\n",
      "Scenario_5_monitor_node_1_preamp_lpth_3-2_1_sp1_w10.dat\n",
      "current shape of X: (259090, 6)\n",
      "current shape of y: (259090,)\n",
      "Scenario_6_monitor_node_1_preamp_lpth_3-2_1_100GHz_sp1_w10.dat\n",
      "current shape of X: (259681, 6)\n",
      "current shape of y: (259681,)\n",
      "Scenario_6_monitor_node_1_preamp_lpth_3-2_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (259972, 6)\n",
      "current shape of y: (259972,)\n",
      "Scenario_6_monitor_node_1_preamp_lpth_3-2_1_25GHz_sp1_w10.dat\n",
      "current shape of X: (260263, 6)\n",
      "current shape of y: (260263,)\n",
      "Scenario_7_monitor_node_1_preamp_lpth_2_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (281854, 6)\n",
      "current shape of y: (281854,)\n",
      "Scenario_7_monitor_node_1_preamp_lpth_3-1_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (303445, 6)\n",
      "current shape of y: (303445,)\n",
      "Scenario_7_monitor_node_1_preamp_lpth_3-2_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (325036, 6)\n",
      "current shape of y: (325036,)\n",
      "Scenario_8_monitor_node_1_preamp_lpth_2_1_50GHz_sp1_w10.dat\n",
      "current shape of X: (346627, 6)\n",
      "current shape of y: (346627,)\n",
      "Scenario_8_monitor_node_1_preamp_lpth_3-1_1_50GHz_sp1_w10.dat\n",
      "current shape of X: (368218, 6)\n",
      "current shape of y: (368218,)\n",
      "Scenario_8_monitor_node_1_preamp_lpth_3-2_1_50GHz_sp1_w10.dat\n",
      "current shape of X: (389809, 6)\n",
      "current shape of y: (389809,)\n",
      "[[18.815 18.815  0.141  0.052 18.893 18.752]\n",
      " [18.816 18.816  0.141  0.052 18.893 18.752]\n",
      " [18.824 18.824  0.141  0.048 18.893 18.752]\n",
      " ...\n",
      " [24.105 24.105  0.109  0.033 24.166 24.057]\n",
      " [24.117 24.117  0.099  0.035 24.175 24.076]\n",
      " [24.123 24.123  0.099  0.036 24.175 24.076]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "(389809, 6)\n",
      "(389809,)\n",
      "[[-0.34193409 -0.34195533  0.39904486  0.81321582 -0.33558538 -0.34337995]\n",
      " [-0.34156691 -0.34158816  0.39904486  0.81321582 -0.33558538 -0.34337995]\n",
      " [-0.33862951 -0.33865076  0.39904486  0.56228842 -0.33558538 -0.34337995]\n",
      " ...\n",
      " [ 1.60042239  1.60040113 -0.25180071 -0.37868934  1.59894936  1.60628196]\n",
      " [ 1.60482849  1.60480723 -0.45518995 -0.25322564  1.60225124  1.61326472]\n",
      " [ 1.60703154  1.60701029 -0.45518995 -0.19049379  1.60225124  1.61326472]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "(389809, 6)\n",
      "(389809,)\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "###### Use function load_window_dataset() with datasets of for all scenarios  \n",
    "###### using window length = 10 and spacing = 1. Finally, perform features scaling \n",
    "##########################################################################################\n",
    "\n",
    "X=None \n",
    "y=None\n",
    "length=10\n",
    "spacing=1\n",
    "folderpath='Features_raw'\n",
    "\n",
    "for filename in os.listdir(folderpath):   \n",
    "    if filename.endswith('_sp' + str(spacing) + '_w' + str(length) + '.dat'):\n",
    "        print(filename)\n",
    "        label = 0\n",
    "        if int(filename[9]) > 5:\n",
    "          label = 1\n",
    "        fullname = folderpath + '/' + filename\n",
    "#------------------------------------------------------------\n",
    "        X, y = load_window_dataset(X, y, fullname, label)\n",
    "#------------------------------------------------------------\n",
    "        print('current shape of X: ' +str(X.shape))\n",
    "        print('current shape of y: ' +str(y.shape))\n",
    "\n",
    "#All scenario correlated ONLY TO \"length\" and \"spacing\" variables\n",
    "print(X)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Features scaling \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i6dGWj1QVvCj"
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "###### Perform XGBoost hyperparameters optimization via crossvalidation\n",
    "###### Print hyperparameters obtained with crossvalidation in resfileXGB\n",
    "###### Retrain an XGB model with best hyperparameters using the entire training set (X_train, y_train)\n",
    "###### Print training results (best accuracy and training duration) in resfileXGB\n",
    "###### Return the trained XGB model\n",
    "###### for XGB with given hyperparameters space \n",
    "###### XGB documentation at: https://xgboost.readthedocs.io/en/stable/python/python_intro.html \n",
    "###### XGB hyperparameters: https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html \n",
    "############################################################################################################\n",
    "\n",
    "def train_classifier_XGB(X_train, y_train, resfileXGB): \n",
    "\n",
    "    #F: define the search space for your hyperparameters - a space where to search\n",
    "    # These parameters are needed to balance between underfitting and overfitting\n",
    "    # We are testing 3 hyperparameters: eta, max_depth and subsample\n",
    "    space4xgb = { \n",
    "     'eta': hp.choice('eta', [0.1, 0.3, 0.5, 0.7, 0.9, 1]),\n",
    "     # max_depth (maximum depth of the decision trees being trained)\n",
    "     'max_depth': hp.choice('max_depth', np.arange(1, 20, 2)),\n",
    "     'subsample': hp.choice('subsample', [0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    }\n",
    "\n",
    "    # hyperopt is used to perform an efficent search in the space of parameters\n",
    "    def hyperopt_train_test(params):\n",
    "        model = XGBClassifier(use_label_encoder=False, verbosity = 0, **params)\n",
    "        #F: see https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst\n",
    "        \n",
    "        return cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "        #F: cross_val_score is from scikit learn (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "        #F: will use the default score (for XGB it is accuracy)\n",
    "        #F: this includes also training; cv=5 (5 number of folds) (5-folds crossvalidation)\n",
    "        #F: .mean() is taken as cross_val_score returns an array of scores (one for each fold)\n",
    "        # We have to do the mean because \"cross_val_score\" returns the accuracy of all the folds\n",
    "\n",
    "    #We pass to this function the \"space4xgb\" parameter (in fmin() function)\n",
    "    #F: this function is used below, as a parameter to fmin\n",
    "    def f(params): \n",
    "        # assumes that \"hyperopt_train_test\" gives use the best cross validation accuracy \n",
    "        # given that combination of hyperparameters (params)\n",
    "        acc = hyperopt_train_test(params)\n",
    "        #F: loss is returned as opposite (negative) of accuracy because we will use in \n",
    "        #f_min (that only minimizes), where we want to minimize the loss (i.e., maximize accuracy)\n",
    "        # We need to return these parameters because fmin() requires them\n",
    "        return {'loss': -acc, 'status': STATUS_OK} #F: loss is returned as opposite (negative) of accuracy because we will use in f_min (that only minimizes), where we want to minimize the loss (i.e., maximize accuracy)\n",
    "\n",
    "    trials = Trials()\n",
    "    # best_params stores the index of the best parameters values according to the function\n",
    "    # fmin() returns the indexes based on the minimum value of a passed function \"f\"\n",
    "    # space4xgb is the search space\n",
    "    # algo=tpe.suggest is the used alorithm\n",
    "    # max_evals=5 is the maximum trials\n",
    "    best_params = fmin(f, space4xgb, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "    #F: see: https://github.com/hyperopt/hyperopt/blob/master/hyperopt/fmin.py\n",
    "    #F: at this point, best_param is a dictionary where each key is the index of the corresponding best param in space4xgb\n",
    "    \n",
    "    #Insert in the paramets the values of the hyperparameters (not the indexes)\n",
    "    best_params = hyperopt.space_eval(space4xgb, best_params)\n",
    "    #F: this is used to extract from space4xgb the best values according to the indexes in best_params (and put such values in best_params)\n",
    "    print(best_params)\n",
    "    \n",
    "    best_cv_acc = -round(trials.best_trial['result']['loss'], 2) #F: best across trials\n",
    "    print('best_cv_acc: ' + str(best_cv_acc))\n",
    "\n",
    "    xgb = XGBClassifier(eta = best_params['eta'], max_depth= best_params['max_depth'], \n",
    "                            subsample = best_params['subsample'], use_label_encoder=False, verbosity = 0) \n",
    "\n",
    "    t0 = time.time()\n",
    "    #F: fit() is a function from scikit learn interface for XGB (https://xgboost.readthedocs.io/en/stable/python/python_intro.html#scikit-learn-interface), \n",
    "    # there is also train() that can be used directly with XGB objects (https://xgboost.readthedocs.io/en/stable/python/python_intro.html#training) \n",
    "    xgb.fit(X_train, y_train) \n",
    "    t1 = time.time()\n",
    "\n",
    "    with open(resfileXGB, 'w') as result_file:\n",
    "        result_file.write('Best eta: {}\\n'.format(best_params['eta']))\n",
    "        result_file.write('Best max depth: {}\\n'.format(best_params['max_depth']))\n",
    "        result_file.write('Best subsample: {}\\n'.format(best_params['subsample']))\n",
    "        result_file.write('Crossvalidation accuracy: {}\\n'.format(best_cv_acc))\n",
    "        result_file.write('Training duration for XGB is {} s\\n'.format(round(t1 - t0)))\n",
    "\n",
    "    return xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a0aJlN6lVvCl"
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "###### Perform DNN hyperparameters optimization via crossvalidation\n",
    "###### Print hyperparameters obtained with crossvalidation in resfileDNN\n",
    "###### Retrain a DNN model with best hyperparameters using the entire training set (X_train, y_train)\n",
    "###### Print training results (best accuracy and training duration) in resfileDNN\n",
    "###### Return the trained DNN model\n",
    "############################################################################################################\n",
    "\n",
    "def train_classifier_DNN(X_train, y_train, resfileDNN): \n",
    "\n",
    "    #F: define the search space for your hyperparameters\n",
    "    space4dnn = {\n",
    "     'activation': hp.choice('activation', ['logistic', 'tanh', 'relu']),\n",
    "     'neurons': hp.choice('neurons', [10, 50, 100]),\n",
    "     'layers': hp.choice('layers', np.arange(1, 4, 1))\n",
    "    }\n",
    "\n",
    "    def hyperopt_train_test(params):\n",
    "        size = (params['neurons'],) * params['layers']\n",
    "        dnn = MLPClassifier(hidden_layer_sizes=size, activation=params['activation'],\n",
    "                            solver='adam', learning_rate='invscaling', max_iter=1000)\n",
    "        return cross_val_score(dnn, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    def f(params):\n",
    "        acc = hyperopt_train_test(params)\n",
    "        return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_params = fmin(f, space4dnn, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "    \n",
    "    best_params = hyperopt.space_eval(space4dnn, best_params)\n",
    "    print(best_params) \n",
    "    \n",
    "    best_cv_acc = -round(trials.best_trial['result']['loss'], 2)\n",
    "    print('best_cv_acc: ' + str(best_cv_acc))\n",
    "    \n",
    "    \n",
    "    size = (best_params['neurons'],) * best_params['layers']\n",
    "    dnn = MLPClassifier(hidden_layer_sizes=size, activation=best_params['activation'],\n",
    "                                solver='adam', learning_rate='invscaling', max_iter=1000)\n",
    "\n",
    "    t0 = time.time()\n",
    "    dnn.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    with open(resfileDNN, 'w') as result_file:\n",
    "        result_file.write('Best number of layers: {}\\n'.format(best_params['layers']))\n",
    "        result_file.write('Best number of neurons: {}\\n'.format(best_params['neurons']))\n",
    "        result_file.write('Best activation function: {}\\n'.format(best_params['activation']))\n",
    "        result_file.write('Crossvalidation accuracy: {}\\n'.format(best_cv_acc))\n",
    "        result_file.write('Training duration for DNN is {} s\\n'.format(round(t1 - t0)))\n",
    "\n",
    "    return dnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SHnCDjAsPrmp"
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "###### Perform KNN hyperparameters optimization via crossvalidation\n",
    "###### Print hyperparameters obtained with crossvalidation in resfileKNN\n",
    "###### Retrain a KNN model with best hyperparameters using the entire training set (X_train, y_train)\n",
    "###### Print training results (best accuracy and training duration) in resfileKNN\n",
    "###### Return the trained KNN model\n",
    "############################################################################################################\n",
    "\n",
    "def train_classifier_KNN(X_train, y_train, resfileKNN): \n",
    "\n",
    "    #F: define the search space for your hyperparameters\n",
    "    space4knn = {\n",
    "     'leaf_size': hp.choice('leaf_size', np.arange(1, 50, 1)),\n",
    "     'p': hp.choice('p', [1, 2]),\n",
    "     'n_neighbors': hp.choice('n_neighbors', np.arange(1, 30, 1))\n",
    "    }\n",
    "\n",
    "    def hyperopt_train_test(params):\n",
    "        knn = KNeighborsClassifier(leaf_size=params['leaf_size'], p=params['p'], \n",
    "                                   n_neighbors=params['n_neighbors'])\n",
    "        return cross_val_score(knn, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    def f(params):\n",
    "        acc = hyperopt_train_test(params)\n",
    "        return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_params = fmin(f, space4knn, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "    \n",
    "    best_params = hyperopt.space_eval(space4knn, best_params)\n",
    "    print(best_params) \n",
    "    \n",
    "    best_cv_acc = -round(trials.best_trial['result']['loss'], 2)\n",
    "    print('best_cv_acc: ' + str(best_cv_acc))\n",
    "    \n",
    "    knn = KNeighborsClassifier(leaf_size=best_params['leaf_size'], p=best_params['p'], \n",
    "                                   n_neighbors=best_params['n_neighbors'])\n",
    "\n",
    "    t0 = time.time()\n",
    "    knn.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    with open(resfileKNN, 'w') as result_file:\n",
    "        result_file.write('Best leaf_size: {}\\n'.format(best_params['leaf_size']))\n",
    "        result_file.write('Best number of p: {}\\n'.format(best_params['p']))\n",
    "        result_file.write('Best number of neighbors: {}\\n'.format(best_params['n_neighbors']))\n",
    "        result_file.write('Crossvalidation accuracy: {}\\n'.format(best_cv_acc))\n",
    "        result_file.write('Training duration for kNN is {} s\\n'.format(round(t1 - t0)))\n",
    "\n",
    "    return knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF7AXS_bVvCl",
    "outputId": "f6fff8fd-3a66-4554-a277-782e6000d604",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGB...\n",
      "100%|██████████| 5/5 [02:53<00:00, 34.64s/trial, best loss: -0.9992303916756216]\n",
      "{'eta': 0.7, 'max_depth': 7, 'subsample': 1}\n",
      "best_cv_acc: 1.0\n",
      "Training DNN...\n",
      "100%|██████████| 5/5 [21:38<00:00, 259.68s/trial, best loss: -0.998431464219388] \n",
      "{'activation': 'tanh', 'layers': 2, 'neurons': 50}\n",
      "best_cv_acc: 1.0\n",
      "Training KNN...\n",
      "100%|██████████| 5/5 [00:48<00:00,  9.74s/trial, best loss: -0.997386995237138] \n",
      "{'leaf_size': 43, 'n_neighbors': 14, 'p': 1}\n",
      "best_cv_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################\n",
    "###### Split into into train/test and call train_classifier_XXX() functions\n",
    "################################################################################################################\n",
    "res_folder = 'Hyperparameter_optimization'\n",
    "if not os.path.exists(res_folder):\n",
    "    os.makedirs(res_folder)\n",
    "\n",
    "resfile_XGB=res_folder + '/XGB_sp_' + str(spacing) + 'w_' + str(length) + '_results.txt'\n",
    "resfile_DNN=res_folder + '/DNN_sp_' + str(spacing) + 'w_' + str(length) + '_results.txt'\n",
    "resfile_KNN=res_folder + '/KNN_sp_' + str(spacing) + 'w_' + str(length) + '_results.txt'\n",
    "\n",
    "# Stratify garantees the split all the scenarios among train and test\n",
    "# It's like shuffle and split\n",
    "# random_state it's a seed to get the same output\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Training XGB...')\n",
    "xgb = train_classifier_XGB(X_train, y_train, resfile_XGB)\n",
    "\n",
    "print('Training DNN...')\n",
    "dnn = train_classifier_DNN(X_train, y_train, resfile_DNN)\n",
    "\n",
    "print('Training KNN...')\n",
    "knn = train_classifier_KNN(X_train, y_train, resfile_KNN)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
