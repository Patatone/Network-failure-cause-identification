{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Patatone/Network-failure-cause-identification/blob/main/Failure_cause_identification_with_different_failures_location_IPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f-Dgj8rcVvCZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "import time\n",
    "import sklearn.metrics as mt\n",
    "import pickle\n",
    "\n",
    "from xgboost import Booster\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#XAI-related packages: LIME and SHAP\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap \n",
    "import shap.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wtkni_HDVvCg"
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "###### The function load_window_dataset() that takes in input window data file, and \n",
    "###### label to be assigned and returns numpy arrays with features and labels\n",
    "#################################################################################################\n",
    "\n",
    "def load_window_dataset(X, y, filename, label):\n",
    "#Inputs: - X: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only features)\n",
    "#        - y: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only labels)\n",
    "#        - filename: full name (with path) of the file to be read (it must be a window dataset file created above)\n",
    "#        - label: integer, label to be assigned to the datapoints retrieved from filename; it may differ from labels already included in current y\n",
    "#Outputs: - X: updated X (including features for the new data points retrieved from filename)\n",
    "#         - y: updated y (including labels for the new data points)\n",
    "#This function to X and y in input the new datapoints retrieved from filename and return updated X and y\n",
    "#The function handle the case when X and y are empty (initialized as None)\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    if X is None:\n",
    "        X = data.to_numpy()\n",
    "        # full() function puts in all X.shape[0] elements the value \"label\"\n",
    "        y = np.full(X.shape[0], label)\n",
    "    else:\n",
    "        X_temp = data.to_numpy()\n",
    "        y_temp = np.full(X_temp.shape[0], label)\n",
    "        X = np.append(X, X_temp, axis = 0) #F: axis=0-->stack X and X_temp vertically (increase no of rows)\n",
    "        y = np.append(y, y_temp)\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcvMwMfcVvCi",
    "outputId": "371a06b4-3fa7-42a0-efd9-c045e832947f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario_1_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (21591, 6)\n",
      "current shape of y: (21591,)\n",
      "Scenario_1_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (43182, 6)\n",
      "current shape of y: (43182,)\n",
      "Scenario_1_monitor_node_1_preamp_lpth_3-2_1_sp1_w10.dat\n",
      "current shape of X: (64773, 6)\n",
      "current shape of y: (64773,)\n",
      "Scenario_2_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (86364, 6)\n",
      "current shape of y: (86364,)\n",
      "Scenario_2_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (107955, 6)\n",
      "current shape of y: (107955,)\n",
      "Scenario_3_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (129546, 6)\n",
      "current shape of y: (129546,)\n",
      "Scenario_4_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (151137, 6)\n",
      "current shape of y: (151137,)\n",
      "Scenario_4_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (172728, 6)\n",
      "current shape of y: (172728,)\n",
      "Scenario_4_monitor_node_1_preamp_lpth_3-2_1_sp1_w10.dat\n",
      "current shape of X: (194319, 6)\n",
      "current shape of y: (194319,)\n",
      "Scenario_5_monitor_node_1_preamp_lpth_2_1_sp1_w10.dat\n",
      "current shape of X: (215910, 6)\n",
      "current shape of y: (215910,)\n",
      "Scenario_5_monitor_node_1_preamp_lpth_3-1_1_sp1_w10.dat\n",
      "current shape of X: (237500, 6)\n",
      "current shape of y: (237500,)\n",
      "Scenario_5_monitor_node_1_preamp_lpth_3-2_1_sp1_w10.dat\n",
      "current shape of X: (259090, 6)\n",
      "current shape of y: (259090,)\n",
      "Scenario_6_monitor_node_1_preamp_lpth_3-2_1_100GHz_sp1_w10.dat\n",
      "current shape of X: (259681, 6)\n",
      "current shape of y: (259681,)\n",
      "Scenario_6_monitor_node_1_preamp_lpth_3-2_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (259972, 6)\n",
      "current shape of y: (259972,)\n",
      "Scenario_6_monitor_node_1_preamp_lpth_3-2_1_25GHz_sp1_w10.dat\n",
      "current shape of X: (260263, 6)\n",
      "current shape of y: (260263,)\n",
      "Scenario_7_monitor_node_1_preamp_lpth_2_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (281854, 6)\n",
      "current shape of y: (281854,)\n",
      "Scenario_7_monitor_node_1_preamp_lpth_3-1_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (303445, 6)\n",
      "current shape of y: (303445,)\n",
      "Scenario_7_monitor_node_1_preamp_lpth_3-2_1_12.5GHz_sp1_w10.dat\n",
      "current shape of X: (325036, 6)\n",
      "current shape of y: (325036,)\n",
      "Scenario_8_monitor_node_1_preamp_lpth_2_1_50GHz_sp1_w10.dat\n",
      "current shape of X: (346627, 6)\n",
      "current shape of y: (346627,)\n",
      "Scenario_8_monitor_node_1_preamp_lpth_3-1_1_50GHz_sp1_w10.dat\n",
      "current shape of X: (368218, 6)\n",
      "current shape of y: (368218,)\n",
      "Scenario_8_monitor_node_1_preamp_lpth_3-2_1_50GHz_sp1_w10.dat\n",
      "current shape of X: (389809, 6)\n",
      "current shape of y: (389809,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "###### Use function load_window_dataset() with datasets of for all scenarios  \n",
    "###### using window length = 10 and spacing = 1. Finally, perform features scaling \n",
    "##########################################################################################\n",
    "\n",
    "X=None \n",
    "y=None\n",
    "length=10\n",
    "spacing=1\n",
    "folderpath='../Features'\n",
    "\n",
    "for filename in os.listdir(folderpath):   \n",
    "    if filename.endswith('_sp' + str(spacing) + '_w' + str(length) + '.dat'):\n",
    "        print(filename)\n",
    "        label = 0\n",
    "        if int(filename[9]) > 5:\n",
    "          label = 1\n",
    "        fullname = folderpath + '/' + filename\n",
    "#------------------------------------------------------------\n",
    "        X, y = load_window_dataset(X, y, fullname, label)\n",
    "#------------------------------------------------------------\n",
    "        print('current shape of X: ' +str(X.shape))\n",
    "        print('current shape of y: ' +str(y.shape))\n",
    "\n",
    "# Features scaling \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "all_data = {'mean': [X[:,[1,2,3,4,5]], [n for n in y if n != 0]], 'RMS': [X[:,[0,2,3,4,5]], [n for n in y if n != 1]], \n",
    "            'ptp': [X[:,[0,1,3,4,5]], [n for n in y if n != 2]], 'std': [X[:,[0,1,2,4,5]], [n for n in y if n != 3]], \n",
    "            'max': [X[:,[0,1,2,3,5]], [n for n in y if n != 4]], 'min': [X[:,[0,1,2,3,4]], [n for n in y if n != 5]]}\n",
    "\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i6dGWj1QVvCj"
   },
   "outputs": [],
   "source": [
    "def train_classifier_XGB(X_train, y_train): \n",
    "    xgb = XGBClassifier(eta = 0.7, max_depth= 19, subsample = 0.7, verbosity = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a0aJlN6lVvCl"
   },
   "outputs": [],
   "source": [
    "def train_classifier_DNN(X_train, y_train): \n",
    "    size = (10,) * 3\n",
    "    dnn = MLPClassifier(hidden_layer_sizes=size, activation='logistic',\n",
    "                                solver='adam', learning_rate='invscaling', max_iter=1000)\n",
    "    dnn.fit(X_train, y_train)\n",
    "    return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SHnCDjAsPrmp"
   },
   "outputs": [],
   "source": [
    "def train_classifier_KNN(X_train, y_train): \n",
    "    knn = KNeighborsClassifier(leaf_size=21, p=2, n_neighbors=4)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF7AXS_bVvCl",
    "outputId": "f6fff8fd-3a66-4554-a277-782e6000d604",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m knn_models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m all_models \u001b[38;5;241m=\u001b[39m [xgb_models, dnn_models, knn_models]\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43ma_dict\u001b[49m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Stratify garantees the split all the scenarios among train and test\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# It's like shuffle and split\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# random_state it's a seed to get the same output\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(a_dict[key][\u001b[38;5;241m0\u001b[39m], a_dict[key][\u001b[38;5;241m1\u001b[39m], stratify\u001b[38;5;241m=\u001b[39my, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining XGB without \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a_dict' is not defined"
     ]
    }
   ],
   "source": [
    "################################################################################################################\n",
    "###### Split into into train/test and call train_classifier_XXX() functions\n",
    "################################################################################################################\n",
    "\n",
    "xgb_models = []\n",
    "dnn_models = []\n",
    "knn_models = []\n",
    "\n",
    "all_models = [xgb_models, dnn_models, knn_models]\n",
    "\n",
    "for key in all_data:\n",
    "    # Stratify garantees the split all the scenarios among train and test\n",
    "    # It's like shuffle and split\n",
    "    # random_state it's a seed to get the same output\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_data[key][0], all_data[key][1], stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print('Training XGB without '+ key +'...')\n",
    "    xgb = train_classifier_XGB(X_train, y_train)\n",
    "    xgb_models.append(xgb)\n",
    "    \n",
    "    print('Training MLP without '+ key +'...')\n",
    "    dnn = train_classifier_DNN(X_train, y_train)\n",
    "    dnn_models.append(dnn)\n",
    "    \n",
    "    print('Training KNN without '+ key +'...')\n",
    "    knn = train_classifier_KNN(X_train, y_train)\n",
    "    knn_models.append(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dosJAeJhVvCm"
   },
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "###### The function performance_eval() takes in input ground truth and predicted labels, \n",
    "###### prints results in a result file passed in input, and returns global metrics\n",
    "########################################################################################################\n",
    "\n",
    "def performance_eval(y_true, y_pred, lab, l_names):\n",
    "    \n",
    "    #Compute metrics and print them\n",
    "    accuracy = mt.accuracy_score(y_true, y_pred)\n",
    "    precision = mt.precision_score(y_true, y_pred, labels=lab, average=None) #F: average=None gives per-class results\n",
    "    global_precision = mt.precision_score(y_true, y_pred, labels=lab, average='weighted') \n",
    "    recall = mt.recall_score(y_true, y_pred, labels=lab, average=None)\n",
    "    global_recall = mt.recall_score(y_true, y_pred, labels=lab, average='weighted') \n",
    "    f1score = mt.f1_score(y_true, y_pred, labels=lab, average=None)\n",
    "    global_f1score = mt.f1_score(y_true, y_pred, labels=lab, average='weighted')\n",
    "\n",
    "    return accuracy, global_precision, global_recall, global_f1score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8JqP7U8wVvCm",
    "outputId": "1028f917-309f-438a-cccd-238301046c98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "###### Load models into NEW models, perform prediction and evaluate performance using performance_eval() \n",
    "##############################################################################################################\n",
    "\n",
    "lbl = [0, 1]\n",
    "label_names=['Attenuation', 'Filtering']\n",
    "\n",
    "# Added to fix: 'XGBClassifier' object has no attribute '_le'\n",
    "xgb._le = LabelEncoder().fit(y_test)\n",
    "\n",
    "y_pred_XGB = xgb.predict(X_test)\n",
    "y_pred_DNN = dnn.predict(X_test)\n",
    "y_pred_KNN = knn.predict(X_test)\n",
    "\n",
    "XGB_metrics = performance_eval(y_test, y_pred_XGB, lbl, label_names)\n",
    "DNN_metrics = performance_eval(y_test, y_pred_DNN, lbl, label_names)\n",
    "KNN_metrics = performance_eval(y_test, y_pred_KNN, lbl, label_names)\n",
    "\n",
    "print('XGB metrics: ' +str(XGB_metrics))\n",
    "print('****************')\n",
    "print('DNN metrics: ' +str(DNN_metrics))\n",
    "print('****************')\n",
    "print('KNN metrics: ' +str(KNN_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
