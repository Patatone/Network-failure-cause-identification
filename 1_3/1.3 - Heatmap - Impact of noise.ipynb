{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearnex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearnex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m patch_sklearn\n\u001b[0;32m      2\u001b[0m patch_sklearn()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearnex'"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-Dgj8rcVvCZ"
   },
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "import sklearn.metrics as mt\n",
    "import pickle\n",
    "\n",
    "from xgboost import Booster\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pylab import *\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wtkni_HDVvCg"
   },
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "###### The function load_window_dataset() that takes in input window data file, and \n",
    "###### label to be assigned and returns numpy arrays with features and labels\n",
    "#################################################################################################\n",
    "\n",
    "def load_window_dataset(X, y, filename, label):\n",
    "#Inputs: - X: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only features)\n",
    "#        - y: current matrix of datapoints where we want to APPEND the datapoints retrieved from filename (only labels)\n",
    "#        - filename: full name (with path) of the file to be read (it must be a window dataset file created above)\n",
    "#        - label: integer, label to be assigned to the datapoints retrieved from filename; it may differ from labels already included in current y\n",
    "#Outputs: - X: updated X (including features for the new data points retrieved from filename)\n",
    "#         - y: updated y (including labels for the new data points)\n",
    "#This function to X and y in input the new datapoints retrieved from filename and return updated X and y\n",
    "#The function handle the case when X and y are empty (initialized as None)\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    if X is None:\n",
    "        X = data.to_numpy()\n",
    "        # full() function puts in all X.shape[0] elements the value \"label\"\n",
    "        y = np.full(X.shape[0], label)\n",
    "    else:\n",
    "        X_temp = data.to_numpy()\n",
    "        y_temp = np.full(X_temp.shape[0], label)\n",
    "        X = np.append(X, X_temp, axis = 0) #F: axis=0-->stack X and X_temp vertically (increase no of rows)\n",
    "        y = np.append(y, y_temp)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6dGWj1QVvCj"
   },
   "outputs": [],
   "source": [
    "def train_classifier_XGB(X_train, y_train): \n",
    "    xgb = XGBClassifier(use_label_encoder=False, eta = 0.7, max_depth= 7, subsample = 1, verbosity = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0aJlN6lVvCl"
   },
   "outputs": [],
   "source": [
    "def train_classifier_DNN(X_train, y_train): \n",
    "    size = (50,) * 2\n",
    "    dnn = MLPClassifier(hidden_layer_sizes=size, activation='tanh',\n",
    "                        solver='adam', learning_rate='invscaling', max_iter=1000)\n",
    "    dnn.fit(X_train, y_train)\n",
    "\n",
    "    return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHnCDjAsPrmp"
   },
   "outputs": [],
   "source": [
    "def train_classifier_KNN(X_train, y_train): \n",
    "    knn = KNeighborsClassifier(leaf_size=43, p=1, n_neighbors=14)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dosJAeJhVvCm"
   },
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "###### The function performance_eval() takes in input ground truth and predicted labels, \n",
    "###### prints results in a result file passed in input, and returns global metrics\n",
    "########################################################################################################\n",
    "\n",
    "def performance_eval(y_true, y_pred, lab, l_names):\n",
    "\n",
    "    #Compute metrics and print/write them\n",
    "    accuracy = mt.accuracy_score(y_true, y_pred)\n",
    "    precision = mt.precision_score(y_true, y_pred, labels=lab, average=None) #F: average=None gives per-class results\n",
    "    global_precision = mt.precision_score(y_true, y_pred, labels=lab, average='weighted') \n",
    "    recall = mt.recall_score(y_true, y_pred, labels=lab, average=None)\n",
    "    global_recall = mt.recall_score(y_true, y_pred, labels=lab, average='weighted') \n",
    "    f1score = mt.f1_score(y_true, y_pred, labels=lab, average=None)\n",
    "    global_f1score = mt.f1_score(y_true, y_pred, labels=lab, average='weighted')\n",
    "\n",
    "    return accuracy, global_precision, global_recall, global_f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_intervals = [20, 60, 120, 300, 600]\n",
    "noise_lengths = [3, 5, 7, 15]\n",
    "noise_means = [1, 3, 5, 7, 12]\n",
    "\n",
    "A_XGB = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GP_XGB = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GR_XGB = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GF1_XGB = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "\n",
    "A_DNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GP_DNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GR_DNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GF1_DNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "\n",
    "A_KNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GP_KNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GR_KNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "GF1_KNN = np.zeros([len(noise_intervals),len(noise_lengths),len(noise_means)])\n",
    "\n",
    "def training_loop(noise_lengths, noise_intervals, noise_means):\n",
    "    global A_XGB, GP_XGB, GR_XGB, GF1_XGB\n",
    "    global A_DNN, GP_DNN, GR_DNN, GF1_DNN\n",
    "    global A_KNN, GP_KNN, GR_KNN, GF1_KNN\n",
    "    \n",
    "    lbl = [0, 1]\n",
    "    label_names=['Attenuation', 'Filtering']\n",
    "\n",
    "    spacing = 1\n",
    "    w_length = 10\n",
    "    sampling = 1\n",
    "    \n",
    "    for i, n_interval in enumerate(noise_intervals): #enumerate(range(minsp,maxsp+1,stepsp)):\n",
    "        for j, n_length in enumerate(noise_lengths): #enumerate(range(minlength,maxlength+1,steplength)):\n",
    "            for m, n_mean in enumerate(noise_means):\n",
    "                print('********************************')\n",
    "                print('Iteration for spacing={}; window length={}; noise interval={}; noise length={}; noise mean={}'.format(spacing, w_length, n_interval, n_length, n_mean))\n",
    "\n",
    "                ####### 1) Load dataset #######\n",
    "                print('1) Loading dataset into (XX,yy)...')\n",
    "\n",
    "                XX = None\n",
    "                yy = None\n",
    "                folderpath='../Features_1_3'\n",
    "\n",
    "                for filename in os.listdir(folderpath):\n",
    "                    if filename.endswith('_nm' + str(n_mean) + '_ni' + str(n_interval) + '_nl' + str(n_length) \n",
    "                                         + '_sa' + str(sampling) + '_sp' + str(spacing) + '_w' + str(w_length) + '.dat'):\n",
    "                        label = 0\n",
    "                        if int(filename[9]) > 5:\n",
    "                            label = 1\n",
    "                        fullname = folderpath + '/' + filename\n",
    "                        XX, yy = load_window_dataset(XX, yy, fullname, label)\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                XX = scaler.fit_transform(XX)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(XX, yy, stratify=yy, test_size=0.99, random_state=42)\n",
    "                print('Training XGB...')\n",
    "                xgb = train_classifier_XGB(X_train, y_train)\n",
    "\n",
    "                print('Training DNN...')\n",
    "                dnn = train_classifier_DNN(X_train, y_train)\n",
    "\n",
    "                print('Training KNN...')\n",
    "                knn = train_classifier_KNN(X_train, y_train)\n",
    "\n",
    "                y_pred_XGB = xgb.predict(X_test)\n",
    "                y_pred_DNN = dnn.predict(X_test)\n",
    "                y_pred_KNN = knn.predict(X_test)\n",
    "\n",
    "                A_XGB[i,j,m], GP_XGB[i,j,m], GR_XGB[i,j,m], GF1_XGB[i,j,m] = performance_eval(y_test, y_pred_XGB, lbl, label_names)\n",
    "                print(A_XGB[i,j,m], GP_XGB[i,j,m], GR_XGB[i,j,m], GF1_XGB[i,j,m])\n",
    "                A_DNN[i,j,m], GP_DNN[i,j,m], GR_DNN[i,j,m], GF1_DNN[i,j,m] = performance_eval(y_test, y_pred_DNN, lbl, label_names)\n",
    "                print(A_DNN[i,j,m], GP_DNN[i,j,m], GR_DNN[i,j,m], GF1_DNN[i,j,m])\n",
    "                A_KNN[i,j,m], GP_KNN[i,j,m], GR_KNN[i,j,m], GF1_KNN[i,j,m] = performance_eval(y_test, y_pred_KNN, lbl, label_names)\n",
    "                print(A_KNN[i,j,m], GP_KNN[i,j,m], GR_KNN[i,j,m], GF1_KNN[i,j,m])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_folder = '1_3_Figures'\n",
    "if not os.path.exists(fig_folder):\n",
    "    os.makedirs(fig_folder)\n",
    "\n",
    "training_loop(noise_lengths, noise_intervals, noise_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder = '1_3_Figures'\n",
    "if not os.path.exists(fig_folder):\n",
    "    os.makedirs(fig_folder)\n",
    "\n",
    "noise_intervals_x = np.repeat(noise_intervals, len(noise_lengths)*len(noise_means))\n",
    "noise_lengths_y = list(np.repeat(noise_lengths, len(noise_means))) * len(noise_intervals)\n",
    "noise_means_z = noise_means * (len(noise_lengths)*len(noise_intervals))\n",
    "\n",
    "A_XGB = A_XGB.reshape(-1)\n",
    "GP_XGB = GP_XGB.reshape(-1)\n",
    "GR_XGB = GR_XGB.reshape(-1)\n",
    "GF1_XGB = GF1_XGB.reshape(-1)\n",
    "\n",
    "A_DNN = A_DNN.reshape(-1)\n",
    "GP_DNN = GP_DNN.reshape(-1)\n",
    "GR_DNN = GR_DNN.reshape(-1)\n",
    "GF1_DNN = GF1_DNN.reshape(-1)\n",
    "\n",
    "A_KNN = A_KNN.reshape(-1)\n",
    "GP_KNN = GP_KNN.reshape(-1)\n",
    "GR_KNN = GR_KNN.reshape(-1)\n",
    "GF1_KNN = GF1_KNN.reshape(-1)\n",
    "\n",
    "df = pd.DataFrame(list(zip(noise_intervals_x, noise_lengths_y, noise_means_z, A_XGB)),\n",
    "               columns =['X', 'Y', 'Z', 'Accuracy'])\n",
    "#display(df)\n",
    "\n",
    "# creating 3d figures\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "\n",
    "# Value Normalization\n",
    "colors = cm.hsv((A_XGB-min(A_XGB))/(max(A_XGB)-min(A_XGB)))\n",
    "\n",
    "# configuring colorbar\n",
    "color_map = cm.ScalarMappable(cmap=cm.hsv)\n",
    "color_map.set_array(A_XGB)\n",
    "\n",
    "# creating the heatmap\n",
    "img = ax.scatter3D(noise_intervals_x, noise_lengths_y, noise_means_z, c=colors, marker='o')\n",
    "plt.colorbar(color_map)\n",
    "\n",
    "# adding title and labels\n",
    "title = \"XGB Impact of Noise\"\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel('X - Noise Interval')\n",
    "ax.set_ylabel('Y - Noise Length')\n",
    "ax.set_zlabel('Z - Noise Mean')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(fig_folder+'/'+title.replace(\" \", \"_\")+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
